{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "declared-seafood",
   "metadata": {},
   "source": [
    "# Baseline Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boxed-firewall",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "amber-whole",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Niels/Documents/EPFL/Master/DeepLearning/project1\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "involved-baltimore",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ethical-september",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import models as models\n",
    "from train import train\n",
    "from evaluation import model_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimum-binary",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "entertaining-shame",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_round_results(round_results):\n",
    "    \n",
    "    train_loss = []\n",
    "    train_error = []\n",
    "    test_error = []\n",
    "    \n",
    "    \n",
    "    for tr_loss, tr_err, _, te_err in round_results:\n",
    "        train_loss.append(tr_loss)\n",
    "        train_error.append(tr_err)\n",
    "        test_error.append(te_err)\n",
    "        \n",
    "    train_loss = torch.tensor(train_loss)\n",
    "    train_error = torch.tensor(train_error)\n",
    "    test_error = torch.tensor(test_error)\n",
    "    \n",
    "    # Mean of the values per epoch\n",
    "    mean_train_loss = train_loss.mean(dim=0)\n",
    "    mean_train_error = train_error.mean(dim=0)\n",
    "    mean_test_error = test_error.mean(dim=0)\n",
    "    \n",
    "    # Standard deviation of the values per epoch\n",
    "    std_train_loss = train_loss.std(dim=0)\n",
    "    std_train_error = train_error.std(dim=0)\n",
    "    std_test_error = test_error.std(dim=0)\n",
    "    \n",
    "    print(f'Model Results:')\n",
    "    print(f'    Mean Training Loss:  {mean_train_loss[-1]:.2f}')\n",
    "    print(f'    Mean Training Error: {100 * mean_train_error[-1]:.2f}%')\n",
    "    print(f'    Mean Testing Error:  {100 * mean_test_error[-1]:.2f}%')\n",
    "    print()\n",
    "    print(f'    Training Loss STD:   {std_train_loss[-1]:.4f}')\n",
    "    print(f'    Training Error STD:  {100 * std_train_error[-1]:.2f}')\n",
    "    print(f'    Testing Error STD:   {100 * std_test_error[-1]:.2f}')\n",
    "    \n",
    "    plt.figure(figsize=(15, 3))\n",
    "    plt.title('Model Training Loss')\n",
    "    plt.xlabel('EPOCH')\n",
    "    plt.ylabel('LOSS')\n",
    "    plt.plot(range(1, len(mean_train_loss) + 1), mean_train_loss)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(15, 3))\n",
    "    plt.title('Model Error Rate')\n",
    "    plt.xlabel('EPOCH')\n",
    "    plt.ylabel('ERROR RATE (%)')\n",
    "    plt.plot(range(1, len(mean_train_error) + 1), mean_train_error, label='Mean Training Error')\n",
    "    plt.plot(range(1, len(mean_train_error) + 1), mean_test_error, label='Mean Test Error')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smaller-burst",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "continuous-bahrain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Parameters: 50492\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaselineCNN(\n",
       "  (lenet): CustomLeNet5(\n",
       "    (conv_layer_1): Sequential(\n",
       "      (0): Conv2d(2, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (conv_layer_2): Sequential(\n",
       "      (0): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=288, out_features=120, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=120, out_features=84, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=84, out_features=20, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): MLPClassifier(\n",
       "    (fc1): Linear(in_features=20, out_features=10, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (fc2): Linear(in_features=10, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def baseline():\n",
    "    \"\"\" Generates the first baseline \"\"\"\n",
    "    model = models.BaselineCNN()\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    return model, criterion, optimizer\n",
    "    \n",
    "    \n",
    "model, _, _ = baseline()\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Model Parameters: {num_params}')\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "intense-discipline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1\n",
      "Test results:\n",
      "  Train Loss:       0.009\n",
      "  Train Error Rate:  0.10%\n",
      "  Test Error Rate:   25.20%\n",
      "-------------------------------------------------- \n",
      "\n",
      "Round 2\n",
      "Test results:\n",
      "  Train Loss:       0.025\n",
      "  Train Error Rate:  0.70%\n",
      "  Test Error Rate:   20.90%\n",
      "-------------------------------------------------- \n",
      "\n",
      "Round 3\n",
      "Test results:\n",
      "  Train Loss:       0.006\n",
      "  Train Error Rate:  0.10%\n",
      "  Test Error Rate:   21.00%\n",
      "-------------------------------------------------- \n",
      "\n",
      "Round 4\n",
      "Test results:\n",
      "  Train Loss:       0.018\n",
      "  Train Error Rate:  0.50%\n",
      "  Test Error Rate:   20.80%\n",
      "-------------------------------------------------- \n",
      "\n",
      "Round 5\n",
      "Test results:\n",
      "  Train Loss:       0.042\n",
      "  Train Error Rate:  1.50%\n",
      "  Test Error Rate:   27.00%\n",
      "-------------------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rounds = 5\n",
    "epochs = 15\n",
    "batch_size = 25\n",
    "seed = 0\n",
    "\n",
    "round_results_baseline = model_eval(baseline, train, rounds, epochs, batch_size, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotional-calibration",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
